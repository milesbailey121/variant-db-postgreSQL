{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column 1: “seqid” Accession.version of the annotated genomic sequence. NCBI files universally use accession.version because it provides an unambiguous identifier for the annotated sequence, and does not require additional knowledge of the species, assembly and version, and data source. We strongly recommend using accession.version instead of ambiguous seqids such as ‘chr1’ to avoid errors due to mis-associating features with the wrong genomic location.\n",
    "\n",
    "Column 2: “source” For annotations produced by one of NCBI’s pipelines, the method used to generate the annotation is provided in column 2. The method is found in the ModelEvidence object in ASN.1 format, and appears in the flatfile format as a structured note. For example: “Derived by automated computational analysis using gene prediction method: BestRefSeq”\n",
    "\n",
    "The reported methods for RefSeq eukaryotic annotations include:\n",
    "\n",
    "BestRefSeq: feature projected from the alignment of a “known” RefSeq transcript to the genome\n",
    "\n",
    "Curated Genomic: feature projected from the alignment of a curated RefSeq genomic sequence to the genome\n",
    "\n",
    "Gnomon: feature predicted by Gnomon, using transcript and protein evidence and/or ab initio\n",
    "\n",
    "BestRefSeq,Gnomon: gene with children features predicted by BestRefSeq and Gnomon\n",
    "\n",
    "Curated Genomic,Gnomon: gene with children features predicted Curated Genomic or Gnomon\n",
    "\n",
    "tRNAscan-SE: feature predicted by tRNAscan-SE\n",
    "\n",
    "The reported methods for RefSeq prokaryotic annotations include:\n",
    "\n",
    "GeneMarkS+: feature predicted by GeneMarkS+\n",
    "\n",
    "Protein Homology: feature predicted by protein alignment\n",
    "\n",
    "cmsearch: feature predicted by cmsearch\n",
    "\n",
    "tRNAscan-SE: feature predicted by tRNAscan-SE\n",
    "\n",
    "If the annotation method is not available, the source column is based on the source database for the record (RefSeq, GenBank, EMBL, DDBJ).\n",
    "\n",
    "Column 3: “type” The SOFA feature type most equivalent to the feature found in the source annotation. The original GenBank feature type is also provided by the “gbkey” attribute in column 9.\n",
    "\n",
    "Columns 4 & 5: “start” and “end” Start and end coordinates of the feature in 1-based coordinates. Note two exon or CDS rows of the same feature may overlap or be separated by an artificial “micro-intron” in order to represent cases of ribosomal slippage or putative assembly errors. See Additional Details below for more information.\n",
    "\n",
    "Column 6: “score” Currently only provided for alignments, if they contain a score named “score”. The definition of this score may vary depending on the type of alignment.\n",
    "\n",
    "Column 7: “strand” The strand of the feature\n",
    "\n",
    "Column 8: “phase” The phase of the CDS feature, which is related to /codon_start in the flatfile specification. The phase is computed based on the known phase at the start of the CDS and computed for subsequent CDS rows. It may not be accurate if the CDS contains internal frameshifts, which can occur in pseudogenes and in genomes with indels, assembly gaps, and other errors. See Additional Details below for more information.\n",
    "\n",
    "Column 9: “attributes” A semicolon delimited list of official and additional attributes describing the feature.\n",
    "\n",
    "Credit: https://www.ncbi.nlm.nih.gov/datasets/docs/v1/reference-docs/file-formats/about-ncbi-gff3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm \n",
    "from sqlalchemy import URL,engine\n",
    "from config_parse import configargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gff3(fpath):\n",
    "    \"\"\"Parses GFF3 files and extracts both gene and transcript info into seperate dataframes\n",
    "\n",
    "    Args:\n",
    "        fpath (str): File path to GFF3 file\n",
    "\n",
    "    Returns:\n",
    "        gene_df (pandas.core.frame.DataFrame): Dataframe containg gene information\n",
    "        transcript_df (pandas.core.frame.DataFrame): Dataframe containg transcript information containg seperate exons\n",
    "    \"\"\"\n",
    "    # Initialize empty lists to store gene and transcript data\n",
    "    gene_data = []\n",
    "    transcript_data = []\n",
    "    \n",
    "    # Open the GFF3 file\n",
    "    with open(fpath) as gff3:\n",
    "        for line in tqdm.tqdm(gff3):\n",
    "            # Skip header lines\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "\n",
    "            # Split the GFF3 columns\n",
    "            cols = line.strip().split('\\t')\n",
    "            seqid, source, feature_type, start, end, score, strand, phase, attributes = cols\n",
    "            \n",
    "            # Parse attributes into a dictionary\n",
    "            attr_dict = {}\n",
    "            for attr in attributes.split(';'):\n",
    "                key, value = attr.split('=')\n",
    "                attr_dict[key] = value\n",
    "            \n",
    "            # If the feature is a gene, populate the gene table\n",
    "            if feature_type == 'gene':\n",
    "                gene_id = attr_dict.get('ID', '')\n",
    "                gene_name = attr_dict.get('gene_name', '')\n",
    "                gene_type = attr_dict.get('gene_type', '')\n",
    "                \n",
    "                gene_data.append({\n",
    "                    'gene_id': gene_id,\n",
    "                    'gene_name': gene_name,\n",
    "                    'chromosome': seqid,\n",
    "                    'start_position': int(start),\n",
    "                    'end_position': int(end),\n",
    "                    'strand': strand,\n",
    "                    'gene_type': gene_type\n",
    "                })\n",
    "            \n",
    "            # If the feature is a transcript or exon, populate the transcript table\n",
    "            elif feature_type in ['transcript', 'exon']:\n",
    "                transcript_id = attr_dict.get('ID', '')\n",
    "                \n",
    "                # Remove 'exon:' prefix if present\n",
    "                if 'exon:' in transcript_id:\n",
    "                    transcript_id = transcript_id.replace('exon:', '')\n",
    "                \n",
    "                gene_id = attr_dict.get('Parent', '')  # Links to the gene\n",
    "                \n",
    "                # For exons, you'll also want to store exon-specific info\n",
    "                exon_count = None\n",
    "                if feature_type == 'exon':\n",
    "                    exon_count = int(attr_dict.get('exon_number', 0))\n",
    "                \n",
    "                transcript_data.append({\n",
    "                    'transcript_id': transcript_id,\n",
    "                    'gene_id': gene_id,\n",
    "                    'start_position': int(start),\n",
    "                    'end_position': int(end),\n",
    "                    'exon_count': exon_count,\n",
    "                    'strand': strand,\n",
    "                    'score': score\n",
    "                })\n",
    "    \n",
    "    # Convert lists to DataFrames for easy manipulation and database insertion\n",
    "    gene_df = pd.DataFrame(gene_data)\n",
    "    transcript_df = pd.DataFrame(transcript_data)\n",
    "    \n",
    "    return gene_df, transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2223398it [00:14, 152134.99it/s]\n"
     ]
    }
   ],
   "source": [
    "fpath = r\"D:\\GitHub\\variant-db-postgreSQL\\data\\GRCh38.p14.basic.annotation.gff3\"\n",
    "gene_df, transcript_df = parse_gff3(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'postgreSQL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     db_type,db_host,db_name,db_user,db_password,db_port \u001b[38;5;241m=\u001b[39m \u001b[43mconfigargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig file not found, please place in main directory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\GitHub\\variant-db-postgreSQL\\config_parse.py:7\u001b[0m, in \u001b[0;36mconfigargs\u001b[1;34m(fpath)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fpath,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m config_file:\n\u001b[0;32m      5\u001b[0m     connection \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(config_file)\n\u001b[1;32m----> 7\u001b[0m     db_type \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnection\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m     db_config \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnection\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m      9\u001b[0m     db_host \u001b[38;5;241m=\u001b[39m db_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhostname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'postgreSQL'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    db_type,db_host,db_name,db_user,db_password,db_port = configargs(\"config.json\")\n",
    "except FileNotFoundError as e:\n",
    "    print(\"Config file not found, please place in main directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_object = URL.create(\n",
    "    \"postgresql\",\n",
    "    username=db_user,\n",
    "    password=db_password,  \n",
    "    host=db_host,\n",
    "    database=db_name,\n",
    "    port=db_port\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = engine.create_engine(url_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
